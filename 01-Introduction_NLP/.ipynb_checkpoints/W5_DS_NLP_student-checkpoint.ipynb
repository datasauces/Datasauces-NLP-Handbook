
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Amazon's customer reviews\n",
    "**Authors:** Julián Darío Miranda <br>\n",
    "**Sources:** *Correlation One* | *Kaggle.com*<br>\n",
    "**Case presentation time:** 60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Case study\n",
    "\n",
    "**Business Context.** You are a data scientist for a large e-commerce firm. You have tens of thousands of customers writing reviews on products each day. Each review contains textual feedback along with a 1-to-5 star rating system (1 being least satisfied and 5 being most satisfied). The firm wants to quantify customer satisfaction coming from these non-rated interactions to help with further business decisions.\n",
    "\n",
    "**Business Problem.** Your task is to *build models which can identify the sentiment (positive or negative) of each of these non-rated interactions*.\n",
    "\n",
    "**Analytical Context.** The data is a set of reviews in CSV file format. We will combine some text processing procedures to be learnt in this session and classification models to develop algorithms capable of classifying interactions by sentiment.\n",
    "\n",
    "You'll be doing the following in this case:\n",
    "1. Read and analyze the input text data and the corresponding response variables (ratings)\n",
    "2. Perform basic pre-processing to prepare the data for modeling\n",
    "3. Learn and apply various ways of featurizing the reviews text\n",
    "4. Build machine learning models to classify text as either exhibiting positive or negative sentiment (1 or 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP related context\n",
    "\n",
    "Some of the most famous NLP-related success stories come from Google, where it is used to provide answers to vague or misspelled internet searches, as well as fairly understandable machine translations of plain text.\n",
    "\n",
    "There are often a lot of misconceptions around the NLP and its place within machine learning in general. NLP is more than just machine learning applied to words. It has two features that make it intractable for common applications like machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Highly Dimensional\n",
    "\n",
    "Consider the book *One Hundred Years of Solitude*. It has more than 1 million characters. Can we see this as a vector of strings that take values in a space of 1 million dimensions and then apply machine learning methods? This is a very bad idea for two reasons:\n",
    "\n",
    "1. Basic approaches perform terribly well in such dimensional spaces.\n",
    "2. These approaches miss some important rules about language that we all know; for example, that \"yes\", \"yeah\" and \"yayy\" mean the same thing.\n",
    "\n",
    "As a result, a lot of NLP involves finding ways to summarize incredibly long vectors in a concise manner, so that we can explore, analyze, and build models with them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: The text depends on the context (*lexical semantics* )\n",
    "\n",
    "For example, the word *compact* has many uses in English (*homograph terms* ):\n",
    "\n",
    "1. A synonym of *small*\n",
    "2. A verb that describes the action of compressing something\n",
    "3. A verb that describes the action of making something firm or stable\n",
    "4. A small case for makeup.\n",
    "5. A compact car.\n",
    "6. A cassette.\n",
    "\n",
    "All-purpose word-processing packages will have to take care of all of this. The ambiguity of some definitions can lead to misleading results that can be easily fixed by a team that is familiar with the underlying NLP processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the packages for data analysis\n",
    "\n",
    "At first sight, we will use four main packages: ```pandas```,``` numpy```, ```matplotlib``` and ``` seaborn```. Let's import these packages using the keyword ``import``. We will change the name from ``pandas`` to ```pd```,```numpy``` to ```np```,```matplotlib``` to ```plt```and ```seaborn``` to ```sns```, using the keyword ``as``.\n",
    "\n",
    "We will be using the `nltk`, `sklearn`, `collections` and `wordcloud` packages for processing our text component. While we analyze the text, we will be using `sklearn` package again to model our text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install nltk\n",
    "! pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# NLP packages\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Modeling packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pylab import rcParams\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "rcParams['figure.figsize'] = 14, 6\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We will be working with a .csv file that contains information about tens of thousands of customers writing reviews on Amazon products every day. Each review contains textual feedback along with a 1-to-5 star rating system (1 being least satisfied and 5 being most satisfied). In this way, the following attributes are available in the data:\n",
    "\n",
    "1. **ProductId (categorical):** ID of the referenced product by the customer.\n",
    "2. **UserId (categorical):** registered user ID.\n",
    "3. **ProfileName (text):** registered user profile name.\n",
    "4. **HelpfulnessNumerator (numerical):** number of users who found the review helpful.\n",
    "5. **HelpfulnessDenominator (numerical):** Number of users who voted whether the review was helpful or not.\n",
    "6. **Score (ordinal):** rating between 1 and 5.\n",
    "7. **Time (numerical):** timestamp of the review.\n",
    "8. **Summary (text):** brief summary of the review.\n",
    "9. **Text (text):** text of the review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and performing basic analysis of the data\n",
    "\n",
    "As usual the first step is to read the available data and perform some high-level analysis on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",