
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Amazon's customer reviews\n",
    "**Authors:** Julián Darío Miranda <br>\n",
    "**Sources:** *Correlation One* | *Kaggle.com*<br>\n",
    "**Case presentation time:** 60 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Case study\n",
    "\n",
    "**Business Context.** You are a data scientist for a large e-commerce firm. You have tens of thousands of customers writing reviews on products each day. Each review contains textual feedback along with a 1-to-5 star rating system (1 being least satisfied and 5 being most satisfied). The firm wants to quantify customer satisfaction coming from these non-rated interactions to help with further business decisions.\n",
    "\n",
    "**Business Problem.** Your task is to *build models which can identify the sentiment (positive or negative) of each of these non-rated interactions*.\n",
    "\n",
    "**Analytical Context.** The data is a set of reviews in CSV file format. We will combine some text processing procedures to be learnt in this session and classification models to develop algorithms capable of classifying interactions by sentiment.\n",
    "\n",
    "You'll be doing the following in this case:\n",
    "1. Read and analyze the input text data and the corresponding response variables (ratings)\n",
    "2. Perform basic pre-processing to prepare the data for modeling\n",
    "3. Learn and apply various ways of featurizing the reviews text\n",
    "4. Build machine learning models to classify text as either exhibiting positive or negative sentiment (1 or 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP related context\n",
    "\n",
    "Some of the most famous NLP-related success stories come from Google, where it is used to provide answers to vague or misspelled internet searches, as well as fairly understandable machine translations of plain text.\n",
    "\n",
    "There are often a lot of misconceptions around the NLP and its place within machine learning in general. NLP is more than just machine learning applied to words. It has two features that make it intractable for common applications like machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Highly Dimensional\n",
    "\n",
    "Consider the book *One Hundred Years of Solitude*. It has more than 1 million characters. Can we see this as a vector of strings that take values in a space of 1 million dimensions and then apply machine learning methods? This is a very bad idea for two reasons:\n",
    "\n",
    "1. Basic approaches perform terribly well in such dimensional spaces.\n",
    "2. These approaches miss some important rules about language that we all know; for example, that \"yes\", \"yeah\" and \"yayy\" mean the same thing.\n",
    "\n",
    "As a result, a lot of NLP involves finding ways to summarize incredibly long vectors in a concise manner, so that we can explore, analyze, and build models with them later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: The text depends on the context (*lexical semantics* )\n",
    "\n",
    "For example, the word *compact* has many uses in English (*homograph terms* ):\n",
    "\n",
    "1. A synonym of *small*\n",
    "2. A verb that describes the action of compressing something\n",
    "3. A verb that describes the action of making something firm or stable\n",
    "4. A small case for makeup.\n",
    "5. A compact car.\n",
    "6. A cassette.\n",
    "\n",
    "All-purpose word-processing packages will have to take care of all of this. The ambiguity of some definitions can lead to misleading results that can be easily fixed by a team that is familiar with the underlying NLP processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the packages for data analysis\n",
    "\n",
    "At first sight, we will use four main packages: ```pandas```,``` numpy```, ```matplotlib``` and ``` seaborn```. Let's import these packages using the keyword ``import``. We will change the name from ``pandas`` to ```pd```,```numpy``` to ```np```,```matplotlib``` to ```plt```and ```seaborn``` to ```sns```, using the keyword ``as``.\n",
    "\n",
    "We will be using the `nltk`, `sklearn`, `collections` and `wordcloud` packages for processing our text component. While we analyze the text, we will be using `sklearn` package again to model our text features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# NLP packages\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Modeling packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from pylab import rcParams\n",
    "import warnings\n",